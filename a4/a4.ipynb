{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7603918e",
   "metadata": {},
   "source": [
    "# Determining Sentence Sentiment using NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "721e976a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments on hardware type: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# My libraries\n",
    "from src.data_loader import SSTDataPipeline\n",
    "from src.trainer import Trainer\n",
    "from src.models import DynamicRNN\n",
    "from src.plotter import Plotter\n",
    "\n",
    "# Check Device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running experiments on hardware type: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc614315",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 5  # SST-5\n",
    "DROPOUT = 0.5\n",
    "EPOCHS = 15\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Pre-trained Vector Path\n",
    "VECTOR_PATH = \"./data/vector.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f6ca033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Data Pipeline...\n",
      "--> Loading SST splits...\n",
      "downloading trainDevTestTrees_PTB.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "trainDevTestTrees_PTB.zip: 100%|██████████| 790k/790k [00:01<00:00, 514kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting\n",
      "--> Building Vocabulary...\n",
      "    Loading specific vectors: ./data/vector.txt\n",
      "    Success: Vocab built with './data/vector.txt'\n",
      "    Label Mapping: {'very negative': 0, 'negative': 1, 'neutral': 2, 'positive': 3, 'very positive': 4}\n",
      "    Vocab Size: 16581\n",
      "--> Creating Iterators...\n",
      "Data ready. Vocab Size: 16581, Pad Index: 1\n"
     ]
    }
   ],
   "source": [
    "# Initialize Data Pipeline (with vectors)\n",
    "print(\"Initializing Data Pipeline...\")\n",
    "data_pipe = SSTDataPipeline(\n",
    "    vector_path=VECTOR_PATH, batch_size=BATCH_SIZE, device=DEVICE\n",
    ")\n",
    "train_iter, val_iter, test_iter = data_pipe.run()\n",
    "\n",
    "# Get Vocabulary Info\n",
    "VOCAB_SIZE = data_pipe.vocab_size\n",
    "PAD_IDX = data_pipe.get_pad_idx()\n",
    "PRETRAINED_VECTORS = data_pipe.get_embeddings()\n",
    "\n",
    "print(f\"Data ready. Vocab Size: {VOCAB_SIZE}, Pad Index: {PAD_IDX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d631e47",
   "metadata": {},
   "source": [
    "### Part 1: Find the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c73aa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_config = [\n",
    "    # --- Naive RNN ---\n",
    "    {\n",
    "        \"name\": \"1_RNN_Random\",\n",
    "        \"rnn_type\": \"rnn\",\n",
    "        \"n_layers\": 1,\n",
    "        \"bidirectional\": False,\n",
    "        \"use_pretrained\": False,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"2_RNN_Pretrained\",\n",
    "        \"rnn_type\": \"rnn\",\n",
    "        \"n_layers\": 1,\n",
    "        \"bidirectional\": False,\n",
    "        \"use_pretrained\": True,\n",
    "    },\n",
    "    # --- Naive LSTM ---\n",
    "    {\n",
    "        \"name\": \"3_LSTM_Random\",\n",
    "        \"rnn_type\": \"lstm\",\n",
    "        \"n_layers\": 1,\n",
    "        \"bidirectional\": False,\n",
    "        \"use_pretrained\": False,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"4_LSTM_Pretrained\",\n",
    "        \"rnn_type\": \"lstm\",\n",
    "        \"n_layers\": 1,\n",
    "        \"bidirectional\": False,\n",
    "        \"use_pretrained\": True,\n",
    "    },\n",
    "    # --- Naive GRU ---\n",
    "    {\n",
    "        \"name\": \"5_GRU_Random\",\n",
    "        \"rnn_type\": \"gru\",\n",
    "        \"n_layers\": 1,\n",
    "        \"bidirectional\": False,\n",
    "        \"use_pretrained\": False,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"6_GRU_Pretrained\",\n",
    "        \"rnn_type\": \"gru\",\n",
    "        \"n_layers\": 1,\n",
    "        \"bidirectional\": False,\n",
    "        \"use_pretrained\": True,\n",
    "    },\n",
    "    # --- Better LSTM (Bi-Directional, 2 Layers) ---\n",
    "    {\n",
    "        \"name\": \"7_BiLSTM_Deep_Random\",\n",
    "        \"rnn_type\": \"lstm\",\n",
    "        \"n_layers\": 2,\n",
    "        \"bidirectional\": True,\n",
    "        \"use_pretrained\": False,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"8_BiLSTM_Deep_Pretrained\",\n",
    "        \"rnn_type\": \"lstm\",\n",
    "        \"n_layers\": 2,\n",
    "        \"bidirectional\": True,\n",
    "        \"use_pretrained\": True,\n",
    "    },\n",
    "    # --- Better GRU (Bi-Directional, 2 Layers) ---\n",
    "    {\n",
    "        \"name\": \"9_BiGRU_Deep_Random\",\n",
    "        \"rnn_type\": \"gru\",\n",
    "        \"n_layers\": 2,\n",
    "        \"bidirectional\": True,\n",
    "        \"use_pretrained\": False,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"10_BiGRU_Deep_Pretrained\",\n",
    "        \"rnn_type\": \"gru\",\n",
    "        \"n_layers\": 2,\n",
    "        \"bidirectional\": True,\n",
    "        \"use_pretrained\": True,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51142c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Running: 1_RNN_Random ====================\n",
      "Starting 1_RNN_Random | Params: 5,118,433\n",
      "  Epoch: 01 | Time: 0m 7s | Train Accuracy: 0.256 | Val Accuracy: 0.261\n",
      "  Epoch: 02 | Time: 0m 7s | Train Accuracy: 0.283 | Val Accuracy: 0.298\n",
      "  Epoch: 03 | Time: 0m 7s | Train Accuracy: 0.316 | Val Accuracy: 0.318\n",
      "  Epoch: 04 | Time: 0m 8s | Train Accuracy: 0.345 | Val Accuracy: 0.328\n",
      "  Epoch: 05 | Time: 0m 7s | Train Accuracy: 0.378 | Val Accuracy: 0.333\n",
      "  Epoch: 06 | Time: 0m 7s | Train Accuracy: 0.403 | Val Accuracy: 0.332\n",
      "  Epoch: 07 | Time: 0m 7s | Train Accuracy: 0.432 | Val Accuracy: 0.316\n",
      "  Epoch: 08 | Time: 0m 8s | Train Accuracy: 0.460 | Val Accuracy: 0.320\n",
      "  Epoch: 09 | Time: 0m 7s | Train Accuracy: 0.483 | Val Accuracy: 0.337\n",
      "  Epoch: 10 | Time: 0m 8s | Train Accuracy: 0.497 | Val Accuracy: 0.313\n",
      "  Epoch: 11 | Time: 0m 8s | Train Accuracy: 0.524 | Val Accuracy: 0.323\n",
      "  Epoch: 12 | Time: 0m 8s | Train Accuracy: 0.547 | Val Accuracy: 0.318\n",
      "  Epoch: 13 | Time: 0m 8s | Train Accuracy: 0.575 | Val Accuracy: 0.325\n",
      "  Epoch: 14 | Time: 0m 7s | Train Accuracy: 0.579 | Val Accuracy: 0.318\n",
      "  Epoch: 15 | Time: 0m 7s | Train Accuracy: 0.604 | Val Accuracy: 0.331\n",
      "Experiement Complete with Train Accuracy: 0.6035, Val Accuracy: 0.3315\n",
      "\n",
      "==================== Running: 2_RNN_Pretrained ====================\n",
      "Loading vectors...\n",
      "Starting 2_RNN_Pretrained | Params: 5,118,433\n",
      "  Epoch: 01 | Time: 0m 7s | Train Accuracy: 0.329 | Val Accuracy: 0.395\n",
      "  Epoch: 02 | Time: 0m 7s | Train Accuracy: 0.390 | Val Accuracy: 0.390\n",
      "  Epoch: 03 | Time: 0m 7s | Train Accuracy: 0.436 | Val Accuracy: 0.379\n",
      "  Epoch: 04 | Time: 0m 7s | Train Accuracy: 0.471 | Val Accuracy: 0.401\n",
      "  Epoch: 05 | Time: 0m 7s | Train Accuracy: 0.538 | Val Accuracy: 0.399\n",
      "  Epoch: 06 | Time: 0m 7s | Train Accuracy: 0.585 | Val Accuracy: 0.391\n",
      "  Epoch: 07 | Time: 0m 8s | Train Accuracy: 0.642 | Val Accuracy: 0.387\n",
      "  Epoch: 08 | Time: 0m 8s | Train Accuracy: 0.664 | Val Accuracy: 0.358\n",
      "  Epoch: 09 | Time: 0m 8s | Train Accuracy: 0.718 | Val Accuracy: 0.311\n",
      "  Epoch: 10 | Time: 0m 7s | Train Accuracy: 0.758 | Val Accuracy: 0.358\n",
      "  Epoch: 11 | Time: 0m 7s | Train Accuracy: 0.798 | Val Accuracy: 0.349\n",
      "  Epoch: 12 | Time: 0m 8s | Train Accuracy: 0.821 | Val Accuracy: 0.368\n",
      "  Epoch: 13 | Time: 0m 7s | Train Accuracy: 0.837 | Val Accuracy: 0.375\n",
      "  Epoch: 14 | Time: 0m 9s | Train Accuracy: 0.863 | Val Accuracy: 0.354\n",
      "  Epoch: 15 | Time: 0m 8s | Train Accuracy: 0.870 | Val Accuracy: 0.356\n",
      "Experiement Complete with Train Accuracy: 0.8698, Val Accuracy: 0.3556\n",
      "\n",
      "==================== Running: 3_LSTM_Random ====================\n",
      "Starting 3_LSTM_Random | Params: 5,546,977\n"
     ]
    }
   ],
   "source": [
    "# Store all results here\n",
    "all_histories = {}  # Key: Model Name, Value: History Dict\n",
    "all_summaries = []  # List of Summary Dicts for DataFrame\n",
    "\n",
    "for config in experiments_config:\n",
    "    print(f\"\\n{'='*20} Running: {config['name']} {'='*20}\")\n",
    "\n",
    "    # 1. Init Model\n",
    "    model = DynamicRNN(\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        hidden_dim=HIDDEN_DIM,\n",
    "        output_dim=OUTPUT_DIM,\n",
    "        n_layers=config[\"n_layers\"],\n",
    "        bidirectional=config[\"bidirectional\"],\n",
    "        dropout=DROPOUT,\n",
    "        pad_idx=PAD_IDX,\n",
    "        rnn_type=config[\"rnn_type\"],\n",
    "    )\n",
    "\n",
    "    # 2. Embeddings\n",
    "    if config[\"use_pretrained\"]:\n",
    "        if PRETRAINED_VECTORS is not None:\n",
    "            print(f\"Loading vectors...\")\n",
    "            model.embedding.weight.data.copy_(PRETRAINED_VECTORS)\n",
    "        else:\n",
    "            print(\"Vectors not found, using random.\")\n",
    "\n",
    "    # 3. Hyperparams for record keeping\n",
    "    hyperparams = {\n",
    "        \"Type\": config[\"rnn_type\"].upper(),\n",
    "        \"BiDir\": config[\"bidirectional\"],\n",
    "        \"Embeds\": \"Pretrained\" if config[\"use_pretrained\"] else \"Random\",\n",
    "        \"Layers\": config[\"n_layers\"],\n",
    "    }\n",
    "\n",
    "    # 4. Train\n",
    "    trainer = Trainer(model, DEVICE)\n",
    "    history, summary = trainer.run_experiment(\n",
    "        train_iter,\n",
    "        val_iter,\n",
    "        epochs=EPOCHS,\n",
    "        lr=LEARNING_RATE,\n",
    "        name=config[\"name\"],\n",
    "        hyperparameters=hyperparams,\n",
    "        save_weights=True,\n",
    "    )\n",
    "\n",
    "    # 5. Store Data\n",
    "    all_histories[config[\"name\"]] = history\n",
    "    all_summaries.append(summary)\n",
    "\n",
    "print(\"\\nAll models trained successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb696c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Generating plots for {len(all_histories)} models...\\n\")\n",
    "\n",
    "# You can adjust grid size or plotting logic here\n",
    "for model_name, history in all_histories.items():\n",
    "    Plotter.plot_history(history, title=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd728bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(all_summaries)\n",
    "\n",
    "# Reorder columns for readability (optional)\n",
    "cols = [\n",
    "    \"Model\",\n",
    "    \"Type\",\n",
    "    \"BiDir\",\n",
    "    \"Embeds\",\n",
    "    \"Best Val Acc\",\n",
    "    \"Best Val Loss\",\n",
    "    \"Time (s)\",\n",
    "    \"Parameters\",\n",
    "]\n",
    "# Filter to ensure columns exist before selecting\n",
    "cols = [c for c in cols if c in df_results.columns]\n",
    "df_results = df_results[cols + [c for c in df_results.columns if c not in cols]]\n",
    "\n",
    "# Display\n",
    "display(df_results.sort_values(by=\"Best Val Acc\", ascending=False))\n",
    "\n",
    "# Export\n",
    "csv_path = \"sst_experiment_results.csv\"\n",
    "df_results.to_csv(csv_path, index=False)\n",
    "print(f\"Results saved to {csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw4-local-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
