{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0ee57744",
      "metadata": {
        "id": "0ee57744"
      },
      "source": [
        "## Step 1: Let's define some model building blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f10e8614",
      "metadata": {
        "id": "f10e8614"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from PIL import Image\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "from tqdm import tqdm  # i like to see progress :)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3886699",
      "metadata": {},
      "outputs": [],
      "source": [
        "import opendatasets as od\n",
        "\n",
        "# to download the dataset from kaggle\n",
        "od.download(\"https://www.kaggle.com/mateuszbuda/lgg-mri-segmentation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4tnJLFfuFKvC",
      "metadata": {
        "id": "4tnJLFfuFKvC"
      },
      "source": [
        "unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "BXT7xzMJFLNQ",
      "metadata": {
        "id": "BXT7xzMJFLNQ"
      },
      "outputs": [],
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"\n",
        "    (Convolution => [BN] => ReLU) * 2\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.enc1 = DoubleConv(in_channels, 64)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.enc2 = DoubleConv(64, 128)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.enc3 = DoubleConv(128, 256)\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.enc4 = DoubleConv(256, 512)\n",
        "        self.pool4 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.bottleneck = DoubleConv(512, 1024)\n",
        "\n",
        "        self.up1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
        "        self.dec1 = DoubleConv(1024, 512)\n",
        "\n",
        "        self.up2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
        "        self.dec2 = DoubleConv(512, 256)\n",
        "\n",
        "        self.up3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.dec3 = DoubleConv(256, 128)\n",
        "\n",
        "        self.up4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.dec4 = DoubleConv(128, 64)\n",
        "\n",
        "        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        e1 = self.enc1(x)\n",
        "        p1 = self.pool1(e1)\n",
        "\n",
        "        e2 = self.enc2(p1)\n",
        "        p2 = self.pool2(e2)\n",
        "\n",
        "        e3 = self.enc3(p2)\n",
        "        p3 = self.pool3(e3)\n",
        "\n",
        "        e4 = self.enc4(p3)\n",
        "        p4 = self.pool4(e4)\n",
        "\n",
        "        # Bottleneck\n",
        "        b = self.bottleneck(p4)\n",
        "\n",
        "        # Decoder\n",
        "        d1 = self.up1(b)\n",
        "        # No cropping needed because padding=1 preserves dimensions\n",
        "        d1 = torch.cat((e4, d1), dim=1)\n",
        "        d1 = self.dec1(d1)\n",
        "\n",
        "        d2 = self.up2(d1)\n",
        "        d2 = torch.cat((e3, d2), dim=1)\n",
        "        d2 = self.dec2(d2)\n",
        "\n",
        "        d3 = self.up3(d2)\n",
        "        d3 = torch.cat((e2, d3), dim=1)\n",
        "        d3 = self.dec3(d3)\n",
        "\n",
        "        d4 = self.up4(d3)\n",
        "        d4 = torch.cat((e1, d4), dim=1)\n",
        "        d4 = self.dec4(d4)\n",
        "\n",
        "        return self.final_conv(d4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aAaiJUmre3R8",
      "metadata": {
        "id": "aAaiJUmre3R8"
      },
      "outputs": [],
      "source": [
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, smooth=1.):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        # Flatten the tensors\n",
        "        inputs = torch.sigmoid(logits).view(-1)\n",
        "        targets = targets.view(-1)\n",
        "\n",
        "        intersection = (inputs * targets).sum()\n",
        "        dice = (2. * intersection + self.smooth) / (inputs.sum() + targets.sum() + self.smooth)\n",
        "\n",
        "        return 1 - dice"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfcc219c",
      "metadata": {
        "id": "dfcc219c"
      },
      "source": [
        "R2Unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f93551a1",
      "metadata": {
        "id": "f93551a1"
      },
      "outputs": [],
      "source": [
        "class RecurrentConvLayer(nn.Module):\n",
        "    def __init__(self, out_channels, t=2):\n",
        "        super().__init__()\n",
        "        self.t = t\n",
        "        self.out_channels = out_channels\n",
        "        self.conv = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        prev_state = x\n",
        "\n",
        "        for _ in range(self.t):\n",
        "            # W_r * x(t-1)\n",
        "            curr_state = self.conv(prev_state)\n",
        "            curr_state = self.bn(curr_state)\n",
        "\n",
        "            curr_state = curr_state + x\n",
        "            prev_state = self.relu(curr_state)\n",
        "\n",
        "        return prev_state\n",
        "\n",
        "\n",
        "class RRCU_Block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, t=2):\n",
        "        super().__init__()\n",
        "        self.conv1x1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        self.ro = RecurrentConvLayer(out_channels, t=t)\n",
        "\n",
        "        if in_channels != out_channels:\n",
        "            self.shortcut = nn.Conv2d(\n",
        "                in_channels, out_channels, kernel_size=1, stride=1\n",
        "            )\n",
        "        else:\n",
        "            self.shortcut = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        path_a = self.conv1x1(x)\n",
        "        path_a = self.ro(path_a)\n",
        "\n",
        "        path_b = self.shortcut(x)\n",
        "\n",
        "        return path_a + path_b\n",
        "\n",
        "\n",
        "class R2UNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=1, t=2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.enc1 = RRCU_Block(in_channels, 64, t=t)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.enc2 = RRCU_Block(64, 128, t=t)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.enc3 = RRCU_Block(128, 256, t=t)\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.enc4 = RRCU_Block(256, 512, t=t)\n",
        "        self.pool4 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.bottleneck = RRCU_Block(512, 1024, t=t)\n",
        "\n",
        "        self.up1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
        "        self.dec1 = RRCU_Block(1024, 512, t=t)  # 1024 because 512(up) + 512(enc4)\n",
        "\n",
        "        self.up2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
        "        self.dec2 = RRCU_Block(512, 256, t=t)  # 512 because 256(up) + 256(enc3)\n",
        "\n",
        "        self.up3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.dec3 = RRCU_Block(256, 128, t=t)\n",
        "\n",
        "        self.up4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.dec4 = RRCU_Block(128, 64, t=t)\n",
        "\n",
        "        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        e1 = self.enc1(x)\n",
        "        p1 = self.pool1(e1)\n",
        "\n",
        "        e2 = self.enc2(p1)\n",
        "        p2 = self.pool2(e2)\n",
        "\n",
        "        e3 = self.enc3(p2)\n",
        "        p3 = self.pool3(e3)\n",
        "\n",
        "        e4 = self.enc4(p3)\n",
        "        p4 = self.pool4(e4)\n",
        "\n",
        "        # Bottleneck\n",
        "        b = self.bottleneck(p4)\n",
        "\n",
        "        # Decoder with Skip Connections\n",
        "        d1 = self.up1(b)\n",
        "        d1 = torch.cat((e4, d1), dim=1)  # Concatenate\n",
        "        d1 = self.dec1(d1)\n",
        "\n",
        "        d2 = self.up2(d1)\n",
        "        d2 = torch.cat((e3, d2), dim=1)\n",
        "        d2 = self.dec2(d2)\n",
        "\n",
        "        d3 = self.up3(d2)\n",
        "        d3 = torch.cat((e2, d3), dim=1)\n",
        "        d3 = self.dec3(d3)\n",
        "\n",
        "        d4 = self.up4(d3)\n",
        "        d4 = torch.cat((e1, d4), dim=1)\n",
        "        d4 = self.dec4(d4)\n",
        "\n",
        "        # Output (No Sigmoid here! We use BCEWithLogitsLoss)\n",
        "        return self.final_conv(d4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17c3096b",
      "metadata": {
        "id": "17c3096b"
      },
      "source": [
        "## Training & Plotting Architecture\n",
        "\n",
        "This needs to do the following:\n",
        "- create an api/function so that if i pass it a model and some data it will invoke the train function\n",
        "- return the model to me so that i can then go on and test the function out\n",
        "- return data related to the loss and accuracy of the modle after each epoch of training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "42bcbb76",
      "metadata": {
        "id": "42bcbb76"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "def _make_optimizer(model, name=\"sgd\", lr=0.05):\n",
        "    name = name.lower()\n",
        "    if name == \"sgd\":\n",
        "        return optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "    if name == \"adam\":\n",
        "        return optim.Adam(model.parameters(), lr=lr)\n",
        "    raise ValueError(f\"Unknown optimizer: {name}\")\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_segmentation(model, loader, device=\"cpu\", criterion=None):\n",
        "    model.eval()\n",
        "    total_pixels, correct_pixels, total_loss = 0, 0, 0.0\n",
        "\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        logits = model(x)\n",
        "\n",
        "        if criterion is not None:\n",
        "            total_loss += criterion(logits, y).item() * x.size(0)\n",
        "\n",
        "        # --- SEGMENTATION METRIC CHANGE ---\n",
        "        # Apply sigmoid to turn logits into probabilities (0 to 1)\n",
        "        preds = torch.sigmoid(logits)\n",
        "        # Threshold at 0.5 to get binary mask (0 or 1)\n",
        "        pred_mask = (preds > 0.5).float()\n",
        "\n",
        "        # Calculate pixel-wise accuracy\n",
        "        correct_pixels += (pred_mask == y).sum().item()\n",
        "        total_pixels += torch.numel(y)  # Total number of pixels in batch\n",
        "\n",
        "    avg_loss = (total_loss / len(loader.dataset)) if criterion is not None else None\n",
        "    acc = correct_pixels / total_pixels\n",
        "    return avg_loss, acc\n",
        "\n",
        "\n",
        "def train_segmentation_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    test_loader,\n",
        "    epochs=15,\n",
        "    optimizer_name=\"adam\",\n",
        "    lr=1e-4,\n",
        "    device=None,\n",
        "    criterion=None\n",
        "):\n",
        "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    if criterion is None:\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    if optimizer_name == \"adam\":\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    else:\n",
        "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "    history = {\"train_loss\": [], \"train_acc\": [], \"test_loss\": [], \"test_acc\": []}\n",
        "    print(f\"\\nStarting training on device: {device.upper()}\")\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss, correct, total_pixels = 0, 0, 0\n",
        "\n",
        "        # Wrap train_loader with tqdm\n",
        "        # desc: Shows \"Epoch 1/15\"\n",
        "        # unit: Shows \"img\" or \"batch\"\n",
        "        loop = tqdm(\n",
        "            enumerate(train_loader, 1),\n",
        "            total=len(train_loader),\n",
        "            desc=f\"Epoch {epoch}/{epochs}\",\n",
        "            leave=True,\n",
        "        )\n",
        "\n",
        "        for step, (x, y) in loop:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * x.size(0)\n",
        "\n",
        "            # Calculate batch accuracy for display\n",
        "            batch_acc = ((torch.sigmoid(logits) > 0.5) == y).float().mean().item()\n",
        "            correct += ((torch.sigmoid(logits) > 0.5) == y).sum().item()\n",
        "            total_pixels += torch.numel(y)\n",
        "\n",
        "            # Update progress bar with current loss and accuracy\n",
        "            loop.set_postfix(loss=loss.item(), acc=batch_acc)\n",
        "\n",
        "        # Calculate epoch metrics\n",
        "        num_samples = len(train_loader.dataset)\n",
        "        train_loss = total_loss / num_samples\n",
        "        train_acc = correct / (total_pixels + 1e-8)\n",
        "\n",
        "        # Run validation\n",
        "        test_loss, test_acc = evaluate_segmentation(\n",
        "            model, test_loader, device, criterion\n",
        "        )\n",
        "\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"train_acc\"].append(train_acc)\n",
        "        history[\"test_loss\"].append(test_loss)\n",
        "        history[\"test_acc\"].append(test_acc)\n",
        "\n",
        "        # We print the summary AFTER the tqdm bar closes for the epoch\n",
        "        print(\n",
        "            f\"Summary: Train Loss: {train_loss:.4f} | Val Loss: {test_loss:.4f} | Val Acc: {test_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "    print(\n",
        "        f\"\\n=== Summary ===\\nTime: {elapsed:.2f}s | Params: {count_parameters(model):,}\"\n",
        "    )\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "408a53ab",
      "metadata": {
        "id": "408a53ab"
      },
      "outputs": [],
      "source": [
        "def test_model(model, test_loader, device=None):\n",
        "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    _, acc = evaluate_segmentation(model, test_loader, device=device, criterion=None)\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "74714365",
      "metadata": {
        "id": "74714365"
      },
      "outputs": [],
      "source": [
        "def plot_history(history, title=\"Training History\"):\n",
        "    \"\"\"\n",
        "    Plots train/test loss and accuracy curves from a history dictionary:\n",
        "    history = {\n",
        "        'train_loss': [...],\n",
        "        'train_acc':  [...],\n",
        "        'test_loss':  [...],\n",
        "        'test_acc':   [...]\n",
        "    }\n",
        "    \"\"\"\n",
        "    epochs = np.arange(1, len(history[\"train_loss\"]) + 1)\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(epochs, history[\"train_loss\"], \"o-\", label=\"Train Loss\")\n",
        "    plt.plot(epochs, history[\"test_loss\"], \"s-\", label=\"Test Loss\")\n",
        "    plt.title(f\"{title} - Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.xticks(epochs)\n",
        "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(epochs, history[\"train_acc\"], \"o-\", label=\"Train Accuracy\")\n",
        "    plt.plot(epochs, history[\"test_acc\"], \"s-\", label=\"Test Accuracy\")\n",
        "    plt.title(f\"{title} - Accuracy\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.xticks(epochs)\n",
        "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2a985b2",
      "metadata": {
        "id": "d2a985b2"
      },
      "source": [
        "## Preparing the Data (MNIST and CIFAR-10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "155b1f49",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "155b1f49",
        "outputId": "f0af9857-6794-46e4-f951-7a4ecc4fff39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MRI data loaded: \n",
            "  Training samples: 3143 \n",
            "  Test samples: 786 \n",
            "  Batch size: 8\n"
          ]
        }
      ],
      "source": [
        "# --- 1. The Minimal Dataset Class ---\n",
        "class MRIDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None, mask_transform=None):\n",
        "        self.transform = transform\n",
        "        self.mask_transform = mask_transform\n",
        "        self.image_paths = []\n",
        "        self.mask_paths = []\n",
        "\n",
        "        # Fast recursive search for all .tif files\n",
        "        # The kaggle_3m dataset usually has subfolders per patient\n",
        "        all_files = glob.glob(os.path.join(root_dir, \"**/*.tif\"), recursive=True)\n",
        "\n",
        "        for file_path in all_files:\n",
        "            # Only pick original images, avoid adding masks twice\n",
        "            if \"_mask\" not in file_path:\n",
        "                self.image_paths.append(file_path)\n",
        "                # Construct mask path: 'image.tif' -> 'image_mask.tif'\n",
        "                self.mask_paths.append(file_path.replace(\".tif\", \"_mask.tif\"))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Open image and mask\n",
        "        image = Image.open(self.image_paths[idx])\n",
        "        mask = Image.open(self.mask_paths[idx])\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.mask_transform:\n",
        "            mask = self.mask_transform(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "\n",
        "# --- 2. Define Transforms ---\n",
        "# Images: Resize, Convert to Tensor, Normalize\n",
        "mri_transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Masks: Resize, Convert to Tensor (No normalization!)\n",
        "mask_transform = transforms.Compose(\n",
        "    [transforms.Resize((256, 256)), transforms.ToTensor()]\n",
        ")\n",
        "\n",
        "# --- 3. Create the Loader ---\n",
        "DATA_DIR = \"./lgg-mri-segmentation/kaggle_3m/\"\n",
        "\n",
        "full_dataset = MRIDataset(\n",
        "    root_dir=DATA_DIR, transform=mri_transform, mask_transform=mask_transform\n",
        ")\n",
        "\n",
        "# Split 80/20 train/test\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "test_size = len(full_dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
        "\n",
        "mri_train_loader = DataLoader(\n",
        "    train_dataset, batch_size=8, shuffle=True, num_workers=2, pin_memory=True\n",
        ")\n",
        "\n",
        "mri_test_loader = DataLoader(\n",
        "    test_dataset, batch_size=8, shuffle=False, num_workers=2, pin_memory=True\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"MRI data loaded:\",\n",
        "    f\"\\n  Training samples: {len(train_dataset)}\",\n",
        "    f\"\\n  Test samples: {len(test_dataset)}\",\n",
        "    f\"\\n  Batch size: {mri_train_loader.batch_size}\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90fb3d28",
      "metadata": {
        "id": "90fb3d28"
      },
      "source": [
        "## Testing Models with Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5d3602d",
      "metadata": {
        "id": "f5d3602d"
      },
      "source": [
        "### Scenerio 1: Base UNet (varying learning rates, adam vs sgd optimizers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "M9qxSkuCOA4E",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9qxSkuCOA4E",
        "outputId": "3525e816-3f45-453e-e86e-86d5c115722a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training on device: CUDA\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10: 100%|██████████| 393/393 [03:03<00:00,  2.14it/s, acc=1, loss=0.0343]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary: Train Loss: 0.1221 | Val Loss: 0.0443 | Val Acc: 0.9905\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10: 100%|██████████| 393/393 [03:03<00:00,  2.14it/s, acc=0.998, loss=0.0213]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary: Train Loss: 0.0401 | Val Loss: 0.0348 | Val Acc: 0.9917\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10: 100%|██████████| 393/393 [03:03<00:00,  2.15it/s, acc=0.995, loss=0.0179]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary: Train Loss: 0.0332 | Val Loss: 0.0298 | Val Acc: 0.9922\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10: 100%|██████████| 393/393 [03:03<00:00,  2.15it/s, acc=0.987, loss=0.0533]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary: Train Loss: 0.0300 | Val Loss: 0.0293 | Val Acc: 0.9918\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10: 100%|██████████| 393/393 [03:03<00:00,  2.14it/s, acc=0.994, loss=0.0296]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary: Train Loss: 0.0279 | Val Loss: 0.0277 | Val Acc: 0.9918\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10: 100%|██████████| 393/393 [03:03<00:00,  2.15it/s, acc=0.997, loss=0.0134]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary: Train Loss: 0.0268 | Val Loss: 0.0260 | Val Acc: 0.9925\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10: 100%|██████████| 393/393 [03:03<00:00,  2.15it/s, acc=0.99, loss=0.0232]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary: Train Loss: 0.0257 | Val Loss: 0.0299 | Val Acc: 0.9901\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10: 100%|██████████| 393/393 [03:03<00:00,  2.15it/s, acc=0.999, loss=0.00942]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary: Train Loss: 0.0251 | Val Loss: 0.0241 | Val Acc: 0.9926\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10:  61%|██████▏   | 241/393 [01:52<01:10,  2.15it/s, acc=0.992, loss=0.0292]"
          ]
        }
      ],
      "source": [
        "base_unet_config = {\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"epochs\": 5,\n",
        "    \"optimizer\": \"sgd\",\n",
        "    \"batch_size\": 32\n",
        "}\n",
        "base_unet_model = UNet(in_channels=3, out_channels=1)\n",
        "base_trained_model, base_model_history = train_segmentation_model(\n",
        "    base_unet_model,\n",
        "    mri_train_loader,\n",
        "    mri_test_loader,\n",
        "    epochs=base_unet_config[\"epochs\"],\n",
        "    optimizer_name=base_unet_config[\"optimizer\"],\n",
        "    lr=base_unet_config[\"learning_rate\"],\n",
        ")\n",
        "\n",
        "plot_history(base_unet_model, title=\"R2U-Net - MRI Segmentation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4TWTbQzXExpm",
      "metadata": {
        "id": "4TWTbQzXExpm"
      },
      "outputs": [],
      "source": [
        "new_unet_config_1 = {\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"epochs\": 10,\n",
        "    \"optimizer\": \"adam\",\n",
        "    \"batch_size\": 32\n",
        "}\n",
        "new_unet_model_1 = UNet(in_channels=3, out_channels=1)\n",
        "new_trained_model_1, new_model_history_1 = train_segmentation_model(\n",
        "    new_unet_model_1,\n",
        "    mri_train_loader,\n",
        "    mri_test_loader,\n",
        "    epochs=new_unet_config_1[\"epochs\"],\n",
        "    optimizer_name=new_unet_config_1[\"optimizer\"],\n",
        "    lr=new_unet_config_1[\"learning_rate\"],\n",
        ")\n",
        "\n",
        "plot_history(new_model_history_1, title=\"R2U-Net - MRI Segmentation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40Z_7PHGR5k7",
      "metadata": {
        "id": "40Z_7PHGR5k7"
      },
      "outputs": [],
      "source": [
        "new_unet_config_2 = {\n",
        "    \"learning_rate\": 0.0001,\n",
        "    \"epochs\": 5,\n",
        "    \"optimizer\": \"adam\",\n",
        "    \"batch_size\": 32\n",
        "}\n",
        "new_unet_model_2 = UNet(in_channels=3, out_channels=1)\n",
        "new_trained_model_2, new_model_history_2 = train_segmentation_model(\n",
        "    new_unet_model_2,\n",
        "    mri_train_loader,\n",
        "    mri_test_loader,\n",
        "    epochs=new_unet_config_2[\"epochs\"],\n",
        "    optimizer_name=new_unet_config_2[\"optimizer\"],\n",
        "    lr=new_unet_config_2[\"learning_rate\"],\n",
        ")\n",
        "\n",
        "plot_history(new_model_history_2, title=\"R2U-Net - MRI Segmentation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12O7Q7AIhuxt",
      "metadata": {
        "id": "12O7Q7AIhuxt"
      },
      "outputs": [],
      "source": [
        "dice_config = {\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"epochs\": 5,\n",
        "    \"optimizer\": \"adam\",\n",
        "    \"batch_size\": 16\n",
        "}\n",
        "dice_unet_model = UNet(in_channels=3, out_channels=1)\n",
        "\n",
        "dice_trained_model, dice_history = train_segmentation_model(\n",
        "    dice_unet_model,\n",
        "    mri_train_loader,\n",
        "    mri_test_loader,\n",
        "    epochs=dice_config[\"epochs\"],\n",
        "    optimizer_name=dice_config[\"optimizer\"],\n",
        "    lr=dice_config[\"learning_rate\"],\n",
        "    criterion=DiceLoss()\n",
        ")\n",
        "\n",
        "plot_history(dice_history, title=\"Standard UNet with Dice Loss\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31a76e43",
      "metadata": {
        "id": "31a76e43"
      },
      "outputs": [],
      "source": [
        "r2unet_config = {\"learning_rate\": 1e-4, \"epochs\": 5, \"optimizer\": \"sgd\", \"batch_size\": 16}\n",
        "r2unet_model = R2UNet(in_channels=3, out_channels=1, t=2)\n",
        "r2unet_trained_model, r2unet_model_history = train_segmentation_model(\n",
        "    r2unet_model,\n",
        "    mri_train_loader,\n",
        "    mri_test_loader,\n",
        "    epochs=r2unet_config[\"epochs\"],\n",
        "    optimizer_name=r2unet_config[\"optimizer\"],\n",
        "    lr=r2unet_config[\"learning_rate\"],\n",
        ")\n",
        "\n",
        "plot_history(r2unet_model_history, title=\"R2U-Net - MRI Segmentation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HdfDBJxsUFHJ",
      "metadata": {
        "id": "HdfDBJxsUFHJ"
      },
      "outputs": [],
      "source": [
        "r2unet_config = {\"learning_rate\": 1e-4, \"epochs\": 3, \"optimizer\": \"adam\", \"batch_size\": 16}\n",
        "r2unet_model = R2UNet(in_channels=3, out_channels=1, t=2)\n",
        "r2unet_trained_model, r2unet_model_history = train_segmentation_model(\n",
        "    r2unet_model,\n",
        "    mri_train_loader,\n",
        "    mri_test_loader,\n",
        "    epochs=r2unet_config[\"epochs\"],\n",
        "    optimizer_name=r2unet_config[\"optimizer\"],\n",
        "    lr=r2unet_config[\"learning_rate\"],\n",
        ")\n",
        "\n",
        "plot_history(r2unet_model_history, title=\"R2U-Net - MRI Segmentation\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
