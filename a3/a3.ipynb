{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ee57744",
   "metadata": {},
   "source": [
    "## Step 1: Let's define some model building blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10e8614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcc219c",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93551a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, activation=\"sigmoid\"):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "        # Activation\n",
    "        if activation == \"sigmoid\":\n",
    "            self.activation = nn.Sigmoid()\n",
    "        elif activation == \"relu\":\n",
    "            self.activation = nn.ReLU()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation: {activation}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f92426",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PureConvCNN(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=10, activation=\"sigmoid\"):\n",
    "        super().__init__()\n",
    "\n",
    "        # --- Activation selection ---\n",
    "        if activation == \"sigmoid\":\n",
    "            self.act = nn.Sigmoid()\n",
    "        elif activation == \"relu\":\n",
    "            self.act = nn.ReLU()\n",
    "        elif activation == \"tanh\":\n",
    "            self.act = nn.Tanh()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation: {activation}\")\n",
    "\n",
    "        # --- Network architecture ---\n",
    "        self.conv1 = nn.Conv2d(in_channels, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.classifier = nn.Conv2d(32, num_classes, kernel_size=7, stride=1, padding=0)\n",
    "        self.global_avg = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.act(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.classifier(x)\n",
    "        x = self.global_avg(x)\n",
    "        x = torch.flatten(x, 1)  # (batch, num_classes)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c3096b",
   "metadata": {},
   "source": [
    "## Training & Plotting Architecture\n",
    "\n",
    "This needs to do the following:\n",
    "- create an api/function so that if i pass it a model and some data it will invoke the train function\n",
    "- return the model to me so that i can then go on and test the function out \n",
    "- return data related to the loss and accuracy of the modle after each epoch of training\n",
    "\n",
    "something like \n",
    "\n",
    "trainModel(model, data, hyperparmeters, etc...) -> [trained]_model, accuracy_per_iteration, loss_per_iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bcbb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_optimizer(model, name=\"sgd\", lr=0.05):\n",
    "    name = name.lower()\n",
    "    if name == \"sgd\":\n",
    "        return optim.SGD(model.parameters(), lr=lr)\n",
    "    if name == \"adam\":\n",
    "        return optim.Adam(model.parameters(), lr=lr)\n",
    "    raise ValueError(f\"Unknown optimizer: {name}\")\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device=\"cpu\", criterion=None):\n",
    "    model.eval()\n",
    "    total, correct, total_loss = 0, 0, 0.0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits = model(x)\n",
    "        if criterion is not None:\n",
    "            total_loss += criterion(logits, y).item() * x.size(0)\n",
    "        correct += (logits.argmax(1) == y).sum().item()\n",
    "        total += x.size(0)\n",
    "    avg_loss = (total_loss / total) if criterion is not None else None\n",
    "    acc = correct / total\n",
    "    return avg_loss, acc\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    epochs=15,\n",
    "    optimizer_name=\"sgd\",\n",
    "    lr=0.05,\n",
    "    device=None,\n",
    "    log_every=100,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train on `train_loader`, evaluate on `test_loader` each epoch.\n",
    "    Returns (trained_model, history) where:\n",
    "      history = {\n",
    "        'train_loss': [...], 'train_acc': [...],\n",
    "        'test_loss':  [...], 'test_acc':  [...]\n",
    "      }\n",
    "    \"\"\"\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Loss + optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = _make_optimizer(model, optimizer_name, lr)\n",
    "\n",
    "    history = {\"train_loss\": [], \"train_acc\": [], \"test_loss\": [], \"test_acc\": []}\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total, correct, total_loss = 0, 0, 0.0\n",
    "\n",
    "        for step, (x, y) in enumerate(train_loader, 1):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            correct += (logits.argmax(1) == y).sum().item()\n",
    "            total += x.size(0)\n",
    "\n",
    "            if log_every and (step % log_every == 0):\n",
    "                print(f\"epoch {epoch} step {step}: loss={loss.item():.4f}\")\n",
    "\n",
    "        # per-epoch metrics\n",
    "        train_loss = total_loss / total\n",
    "        train_acc = correct / total\n",
    "        test_loss, test_acc = evaluate(\n",
    "            model, test_loader, device=device, criterion=criterion\n",
    "        )\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"test_loss\"].append(test_loss)\n",
    "        history[\"test_acc\"].append(test_acc)\n",
    "\n",
    "        print(\n",
    "            f\"[{epoch}/{epochs}] \"\n",
    "            f\"train_loss={train_loss:.4f} train_acc={train_acc:.4f} | \"\n",
    "            f\"test_loss={test_loss:.4f} test_acc={test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408a53ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, device=None):\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    _, acc = evaluate(model, test_loader, device=device, criterion=None)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74714365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, title=\"Training History\"):\n",
    "    \"\"\"\n",
    "    Plots train/test loss and accuracy curves from a history dictionary:\n",
    "    history = {\n",
    "        'train_loss': [...],\n",
    "        'train_acc':  [...],\n",
    "        'test_loss':  [...],\n",
    "        'test_acc':   [...]\n",
    "    }\n",
    "    \"\"\"\n",
    "    epochs = np.arange(1, len(history[\"train_loss\"]) + 1)\n",
    "\n",
    "    # ---- Plot Loss ----\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(epochs, history[\"train_loss\"], \"o-\", label=\"Train Loss\")\n",
    "    plt.plot(epochs, history[\"test_loss\"], \"s-\", label=\"Test Loss\")\n",
    "    plt.title(f\"{title} - Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xticks(epochs)\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # ---- Plot Accuracy ----\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(epochs, history[\"train_acc\"], \"o-\", label=\"Train Accuracy\")\n",
    "    plt.plot(epochs, history[\"test_acc\"], \"s-\", label=\"Test Accuracy\")\n",
    "    plt.title(f\"{title} - Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xticks(epochs)\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a985b2",
   "metadata": {},
   "source": [
    "## Preparing the Data (MNIST and CIFAR-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155b1f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    ")\n",
    "\n",
    "mnist_train_dataset = datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=mnist_transform\n",
    ")\n",
    "mnist_test_dataset = datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=mnist_transform\n",
    ")\n",
    "\n",
    "mnist_train_loader = torch.utils.data.DataLoader(\n",
    "    mnist_train_dataset, batch_size=64, shuffle=True, num_workers=2, pin_memory=True\n",
    ")\n",
    "mnist_test_loader = torch.utils.data.DataLoader(\n",
    "    mnist_test_dataset, batch_size=1000, shuffle=False, num_workers=2, pin_memory=True\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"MNIST data loaded:\",\n",
    "    f\"\\n  Training samples: {len(mnist_train_dataset)}\",\n",
    "    f\"\\n  Test samples: {len(mnist_test_dataset)}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0500234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=(0.4914, 0.4822, 0.4465), std=(0.2470, 0.2435, 0.2616)\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "cifar10_train_dataset = datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=cifar10_transform\n",
    ")\n",
    "cifar10_test_dataset = datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True, transform=cifar10_transform\n",
    ")\n",
    "\n",
    "cifar10_train_loader = torch.utils.data.DataLoader(\n",
    "    cifar10_train_dataset, batch_size=64, shuffle=True, num_workers=2, pin_memory=True\n",
    ")\n",
    "cifar10_test_loader = torch.utils.data.DataLoader(\n",
    "    cifar10_test_dataset, batch_size=1000, shuffle=False, num_workers=2, pin_memory=True\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"CIFAR-10 data loaded:\",\n",
    "    f\"\\n  Training samples: {len(cifar10_train_dataset)}\",\n",
    "    f\"\\n  Test samples: {len(cifar10_test_dataset)}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fb3d28",
   "metadata": {},
   "source": [
    "## Testing Models with Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d3602d",
   "metadata": {},
   "source": [
    "### Scenerio 1: Base Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb1bccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer: SGD; Learning rate: 0.05; BatchSize: 64; Epochs: 15; Loss function: CrossEntropyLoss\n",
    "config = {\"learning_rate\": 0.05, \"epochs\": 15, \"optimizer\": \"sgd\"}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
